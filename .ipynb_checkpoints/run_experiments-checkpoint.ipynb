{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from preprocessing import preprocessing\n",
    "from pca import pca_load\n",
    "from pca_all import pca_load_all\n",
    "from baseline import baseline\n",
    "from nn import nn_load\n",
    "from ae import ae_load\n",
    "#from nn_rf import nn_separate_load\n",
    "\n",
    "from lr import LR\n",
    "from rf import RF\n",
    "from roc import ROC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype = \"binary\"\n",
    "code_type = \"full\"\n",
    "# datatype = \"cont\"\n",
    "filename_add = int(code_type == \"full\")\n",
    "X = pd.read_csv(\"data/stroke_data_\" + datatype + filename_add*\"_full\" + \".csv\")\n",
    "X.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_accuracy = np.zeros((5,5))\n",
    "LR_recall = np.zeros((5,5))\n",
    "RF_accuracy = np.zeros((5,5))\n",
    "RF_recall = np.zeros((5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = 5\n",
    "file_path = 'data/'\n",
    "for i in range(I):\n",
    "    seed = i\n",
    "    X_train, X_test = train_test_split(X, test_size=0.2, random_state=seed)\n",
    "\n",
    "    disease_mapping = {\n",
    "    \"Obesity\": ['E65','E66','E67','E68'], \n",
    "    \"hyperlipidemia\": ['E78'],\n",
    "    \"diabetes\": ['E10','E11','E12','E13','E14'],\n",
    "    \"hypertension\": ['I10','I11','I12','I13','I15'],\n",
    "    \"nicotine\":['F17','Z72'],\n",
    "    \"alcohol\":['F10'],\n",
    "    \"af\":['I48'],\n",
    "    \"heart_diseases\":['I20','I21','I22','I24','I25'],\n",
    "    \"strokes\":['I63','I64','I60','G45','I61'],\n",
    "    }\n",
    "\n",
    "    pca_train, pca_test = pca_load(datatype, disease_mapping, X_train, X_test, code_type, pc0_only=True)\n",
    "    max_train, max_test = baseline(datatype, disease_mapping, \"max\", X_train, X_test)\n",
    "    sum_train, sum_test = baseline(datatype, disease_mapping, \"sum\", X_train, X_test)\n",
    "    nn_train, nn_test = nn_load(datatype, disease_mapping, X_train, X_test, code_type)\n",
    "    ae_train, ae_test = ae_load(datatype, disease_mapping, X_train, X_test, code_type)\n",
    "    # nn_rf_train, nn_rf_test = nn_separate_load(datatype, disease_mapping, X_train, X_test, code_type)\n",
    "\n",
    "    print(pca_train.shape, pca_test.shape)\n",
    "    print(max_train.shape, max_test.shape)\n",
    "    print(sum_train.shape, sum_test.shape)\n",
    "    print(nn_train.shape,nn_test.shape)\n",
    "    print(ae_train.shape,ae_test.shape)\n",
    "    # print(nn_rf_train.shape, nn_rf_test.shape)\n",
    "\n",
    "    Y_scores_sum, accuracy_sum, recall_sum = LR(sum_train,sum_test,tolerance = 1e-4,iter = 4000, seed = seed)\n",
    "    Y_scores_max, accuracy_max, recall_max = LR(max_train,max_test,tolerance = 1e-4,iter = 4000, seed = seed)\n",
    "    Y_scores_pca, accuracy_pca, recall_pca = LR(pca_train,pca_test,tolerance = 1e-4,iter = 4000, seed = seed)\n",
    "    Y_scores_nn, accuracy_nn, recall_nn = LR(nn_train,nn_test,tolerance = 1e-4,iter = 4000, seed = seed)\n",
    "    Y_scores_ae, accuracy_ae, recall_ae = LR(ae_train,ae_test,tolerance = 1e-4,iter = 4000, seed = seed)\n",
    "    Y_scores = [Y_scores_max, Y_scores_sum, Y_scores_pca, Y_scores_ae, Y_scores_nn]\n",
    "    Y_true = pca_test[\"recur\"]\n",
    "\n",
    "    LR_accuracy[i,0] = accuracy_max\n",
    "    LR_accuracy[i,1] = accuracy_sum\n",
    "    LR_accuracy[i,2] = accuracy_pca\n",
    "    LR_accuracy[i,3] = accuracy_ae\n",
    "    LR_accuracy[i,4] = accuracy_nn\n",
    "\n",
    "    LR_recall[i,0] = recall_max\n",
    "    LR_recall[i,1] = recall_sum\n",
    "    LR_recall[i,2] = recall_pca\n",
    "    LR_recall[i,3] = recall_ae\n",
    "    LR_recall[i,4] = recall_nn\n",
    "\n",
    "\n",
    "    file_path = 'data/'\n",
    "    Y_scores = pd.DataFrame(Y_scores)\n",
    "    Y_scores.to_csv(file_path + \"LR_scores_\" + str(seed) + \".csv\", index=False)\n",
    "    Y_scores = Y_scores.values.tolist()\n",
    "    Y_true = pd.DataFrame(Y_true)\n",
    "    Y_true.to_csv(file_path + \"LR_true_\" + str(seed) + \".csv\", index=False)\n",
    "    Y_true = Y_true.values.tolist()\n",
    "    method = [\"max\",\"sum\",\"pca\",\"ae\",\"nn\"]\n",
    "    ROC(Y_true, Y_scores, method, LR = True)\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [100,200,300],  \n",
    "        'max_features': [0.8, 0.9, 1],  \n",
    "        'max_depth': [None, 10, 20, 30],  \n",
    "        'min_samples_split': [2, 5, 10],  \n",
    "        'min_samples_leaf': [1, 2, 4],  \n",
    "        'bootstrap': [True]  \n",
    "    }\n",
    "\n",
    "    Y_scores_sum, accuracy_sum, recall_sum = RF(sum_train,sum_test,params=param_grid)\n",
    "    Y_scores_max, accuracy_max, recall_max = RF(max_train,max_test,params=param_grid)\n",
    "    Y_scores_pca, accuracy_pca, recall_pca = RF(pca_train,pca_test,params=param_grid)\n",
    "    Y_scores_nn, accuracy_nn, recall_nn = RF(nn_train,nn_test,params=param_grid)\n",
    "    Y_scores_ae, accuracy_ae, recall_ae = RF(ae_train,ae_test,params=param_grid)\n",
    "    Y_scores = [Y_scores_max, Y_scores_sum, Y_scores_pca, Y_scores_ae, Y_scores_nn]\n",
    "    Y_true = pca_test[\"recur\"]\n",
    "\n",
    "    RF_accuracy[i,0] = accuracy_max\n",
    "    RF_accuracy[i,1] = accuracy_sum\n",
    "    RF_accuracy[i,2] = accuracy_pca\n",
    "    RF_accuracy[i,3] = accuracy_ae\n",
    "    RF_accuracy[i,4] = accuracy_nn\n",
    "\n",
    "    RF_recall[i,0] = recall_max\n",
    "    RF_recall[i,1] = recall_sum\n",
    "    RF_recall[i,2] = recall_pca\n",
    "    RF_recall[i,3] = recall_ae\n",
    "    RF_recall[i,4] = recall_nn\n",
    "\n",
    "    Y_scores = pd.DataFrame(Y_scores)\n",
    "    Y_scores.to_csv(file_path + \"RF_scores_\" + str(seed) + \".csv\", index=False)\n",
    "    Y_scores = Y_scores.values.tolist()\n",
    "    Y_true = pd.DataFrame(Y_true)\n",
    "    Y_true.to_csv(file_path + \"RF_true_\" + str(seed) + \".csv\", index=False)\n",
    "    Y_true = Y_true.values.tolist()\n",
    "    method = [\"max\",\"sum\",\"pca\",\"ae\",\"nn\"]\n",
    "    ROC(Y_true, Y_scores, method, LR = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/'\n",
    "Y_scores = pd.DataFrame(Y_scores)\n",
    "Y_scores.to_csv(file_path + \"LR_scores_\" + str(seed) + \".csv\", index=False)\n",
    "Y_scores = Y_scores.values.tolist()\n",
    "Y_true = pd.DataFrame(Y_true)\n",
    "Y_true.to_csv(file_path + \"LR_true_\" + str(seed) + \".csv\", index=False)\n",
    "Y_true = Y_true.values.tolist()\n",
    "method = [\"max\",\"sum\",\"pca\",\"ae\",\"nn\"]\n",
    "ROC(Y_true, Y_scores, method, LR = True)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100,200,300],  \n",
    "    'max_features': [0.8, 0.9, 1],  \n",
    "    'max_depth': [None, 10, 20, 30],  \n",
    "    'min_samples_split': [2, 5, 10],  \n",
    "    'min_samples_leaf': [1, 2, 4],  \n",
    "    'bootstrap': [True]  \n",
    "}\n",
    "\n",
    "Y_scores_sum, accuracy_sum, recall_sum = RF(sum_train,sum_test,params=param_grid)\n",
    "Y_scores_max, accuracy_max, recall_max = RF(max_train,max_test,params=param_grid)\n",
    "Y_scores_pca, accuracy_pca, recall_pca = RF(pca_train,pca_test,params=param_grid)\n",
    "Y_scores_nn, accuracy_nn, recall_nn = RF(nn_train,nn_test,params=param_grid)\n",
    "Y_scores_ae, accuracy_ae, recall_ae = RF(ae_train,ae_test,params=param_grid)\n",
    "Y_scores = [Y_scores_max, Y_scores_sum, Y_scores_pca, Y_scores_ae, Y_scores_nn]\n",
    "Y_true = pca_test[\"recur\"]\n",
    "\n",
    "\n",
    "Y_scores = pd.DataFrame(Y_scores)\n",
    "Y_scores.to_csv(file_path + \"RF_scores_\" + str(seed) + \".csv\", index=False)\n",
    "Y_scores = Y_scores.values.tolist()\n",
    "Y_true = pd.DataFrame(Y_true)\n",
    "Y_true.to_csv(file_path + \"RF_true_\" + str(seed) + \".csv\", index=False)\n",
    "Y_true = Y_true.values.tolist()\n",
    "method = [\"max\",\"sum\",\"pca\",\"ae\",\"nn\"]\n",
    "ROC(Y_true, Y_scores, method, LR = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(LR_accuracy).to_csv(file_path+\"LR_accuracy.csv\")\n",
    "pd.DataFrame(LR_recall).to_csv(file_path+\"LR_recall.csv\")\n",
    "pd.DataFrame(RF_accuracy).to_csv(file_path+\"RF_accuracy.csv\")\n",
    "pd.DataFrame(RF_recall).to_csv(file_path+\"RF_recall.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(LR_accuracy,axis=0))\n",
    "print(np.std(LR_accuracy,axis=0))\n",
    "print(np.mean(LR_recall,axis=0))\n",
    "print(np.std(LR_recall,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(RF_accuracy,axis=0))\n",
    "print(np.std(RF_accuracy,axis=0))\n",
    "print(np.mean(RF_recall,axis=0))\n",
    "print(np.std(RF_recall,axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
