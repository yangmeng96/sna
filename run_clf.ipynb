{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd245785",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from preprocessing import preprocessing\n",
    "from pca import pca_load\n",
    "#from pca_all import pca_load_all\n",
    "from baseline import baseline\n",
    "from lr import LR\n",
    "#from lr import LR_P\n",
    "from rf import RF\n",
    "from nn import nn_load\n",
    "from ae import ae_load\n",
    "from nn_rf import nn_separate_load\n",
    "from roc import ROC\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# short code or full code\n",
    "#code_type = \"short\"\n",
    "code_type = \"full\"\n",
    "\n",
    "if code_type == \"short\":\n",
    "    filename = \"main_dataset_final_3\"\n",
    "elif code_type == \"full\":\n",
    "    filename = \"main_dataset_final_3_full_icd10\"\n",
    "    \n",
    "preprocessing(filename)\n",
    "\n",
    "# binary or continuous\n",
    "datatype = \"binary\"\n",
    "# datatype = \"cont\"\n",
    "filename_add = int(code_type == \"full\")\n",
    "X = pd.read_csv(\"data/stroke_data_\" + datatype + filename_add*\"_full\" + \".csv\")\n",
    "#X = pd.read_csv(\"data/stroke_data_binary_full.csv\")\n",
    "\n",
    "X.dropna(inplace=True)\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "\n",
    "# disease_mapping = {\n",
    "#     \"Obesity\": ['E65','E66','E67','E68'], \n",
    "#     \"hyperlipidemia\": ['E78'],\n",
    "#     \"diabetes\": ['E10','E11','E12','E13','E14'],\n",
    "#     \"hypertension\": ['I10','I11','I12','I13','I15'],\n",
    "#     \"nicotine\":['F17','Z72'],\n",
    "#     \"alcohol\":['F10'],\n",
    "#     \"af\":['I48'],\n",
    "#     \"heart_diseases\":['I20','I21','I22','I24','I25'],\n",
    "#     \"strokes\":['I63','I64','I60','G45','I61'],\n",
    "# }\n",
    "\n",
    "# reverse_mapping = {}\n",
    "# for category, codes in disease_mapping.items():\n",
    "#     for code in codes:\n",
    "#         reverse_mapping[code] = category\n",
    "\n",
    "# columns_by_category = {category: [] for category in disease_mapping}\n",
    "\n",
    "# for column in X_train.columns:\n",
    "#     for code in reverse_mapping.keys():\n",
    "#         if column.startswith(code):\n",
    "#             category = reverse_mapping[code]\n",
    "#             columns_by_category[category].append(column)\n",
    "#             break\n",
    "\n",
    "# disease_mapping = columns_by_category\n",
    "# for category, columns in columns_by_category.items():\n",
    "#     print(f\"Category '{category}' has columns: {columns}\")\n",
    "# ###\n",
    "\n",
    "# last_key = next(reversed(columns_by_category))\n",
    "# last_value = columns_by_category[last_key]\n",
    "# X_train[\"stroke\"] = X_train[last_value].sum(axis=1)\n",
    "# X_test[\"stroke\"] = X_test[last_value].sum(axis=1)\n",
    "\n",
    "disease_mapping = {\n",
    "    \"Obesity\": ['E65','E66','E67','E68'], \n",
    "    \"hyperlipidemia\": ['E78'],\n",
    "    \"diabetes\": ['E10','E11','E12','E13','E14'],\n",
    "    \"hypertension\": ['I10','I11','I12','I13','I15'],\n",
    "    \"nicotine\":['F17','Z72'],\n",
    "    \"alcohol\":['F10'],\n",
    "    \"af\":['I48'],\n",
    "    \"heart_diseases\":['I20','I21','I22','I24','I25'],\n",
    "    \"strokes\":['I63','I64','I60','G45','I61'],\n",
    "}\n",
    "\n",
    "# pca vs. baseline\n",
    "train, test = pca_load(datatype, disease_mapping, X_train, X_test, code_type, pc0_only=True)\n",
    "# #X_train, X_test = pca_load_all(datatype, X_train, X_test)\n",
    "max_train, max_test = baseline(datatype, disease_mapping, \"max\", X_train, X_test)\n",
    "sum_train, sum_test = baseline(datatype, disease_mapping, \"sum\", X_train, X_test)\n",
    "nn_train, nn_test = nn_load(datatype, disease_mapping, X_train, X_test, code_type)\n",
    "ae_train, ae_test = ae_load(datatype, disease_mapping, X_train, X_test, code_type)\n",
    "# nn_rf_train, nn_rf_test = nn_separate_load(datatype, disease_mapping, X_train, X_test, code_type)\n",
    "\n",
    "\n",
    "print(train.shape, test.shape)\n",
    "print(max_train.shape, max_test.shape)\n",
    "print(sum_train.shape, sum_test.shape)\n",
    "print(nn_train.shape,nn_test.shape)\n",
    "print(ae_train.shape,ae_test.shape)\n",
    "# print(nn_rf_train.shape, nn_rf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e16955",
   "metadata": {},
   "source": [
    "# Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c4a9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # orginal data with all covariates\n",
    "\n",
    "# X = pd.read_csv(\"data/stroke_data_binary.csv\")\n",
    "# X.dropna(inplace=True)\n",
    "# #X= X[X['race'] != 'Black or African American']\n",
    "# or_train, or_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "# print(\"By Logistic Regression, result for all original predicitors:\")\n",
    "# LR(or_train,or_test,tolerance = 1e-4,iter = 6000, seed = 43)\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100],  \n",
    "#     'max_features': [0.2, 0.4],  \n",
    "#     'max_depth': [10, 20],  \n",
    "#     'min_samples_split': [5, 10],  \n",
    "#     'min_samples_leaf': [2, 4],  \n",
    "#     'bootstrap': [True, False]  \n",
    "# }\n",
    "# print(\"Result for Random Forest, result for all original predicitors:\")\n",
    "# RF(or_train,or_test,params=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70223c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "# We select several comorbidities and demographics as the predictors.\n",
    "\n",
    "# ## baseline: orginal data with the max_aggregation covariates\n",
    "# print(\"By Logistic Regression, result for sum baseline:\")\n",
    "# LR(sum_train,sum_test,tolerance = 1e-4,iter = 4000, seed = 43)\n",
    "# print(\"By Logistic Regression, result for max baseline:\")\n",
    "# LR(max_train,max_test,tolerance = 1e-4,iter = 4000, seed = 43)\n",
    "# ## selected PCA covariates.\n",
    "# print(\"By Logistic Regression, result for PCA:\")\n",
    "# LR(train,test,tolerance = 1e-4,iter = 4000, seed = 43)\n",
    "# print(\"By Logistic Regression, result for NN:\")\n",
    "# LR(nn_train,nn_test,tolerance = 1e-4,iter = 4000, seed = 43)\n",
    "# print(\"By Logistic Regression, result for Autoencoder:\")\n",
    "# LR(ae_train,ae_test,tolerance = 1e-4,iter = 4000, seed = 43)\n",
    "# # print(\"By Logistic Regression, result for NN_RF:\")\n",
    "# # LR(nn_rf_train,nn_rf_test,tolerance = 1e-4,iter = 4000, seed = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c45a731",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_scores_sum, accuracy_sum, recall_sum = LR(sum_train,sum_test,tolerance = 1e-4,iter = 4000, seed = 43)\n",
    "Y_scores_max, accuracy_max, recall_max = LR(max_train,max_test,tolerance = 1e-4,iter = 4000, seed = 43)\n",
    "Y_scores_pca, accuracy_pca, recall_pca = LR(train,test,tolerance = 1e-4,iter = 4000, seed = 43)\n",
    "Y_scores_nn, accuracy_nn, recall_nn = LR(nn_train,nn_test,tolerance = 1e-4,iter = 4000, seed = 43)\n",
    "Y_scores_ae, accuracy_ae, recall_ae = LR(ae_train,ae_test,tolerance = 1e-4,iter = 4000, seed = 43)\n",
    "Y_scores = [Y_scores_sum, Y_scores_max, Y_scores_pca, Y_scores_nn, Y_scores_ae]\n",
    "Y_true = test[\"recur_30\"]\n",
    "\n",
    "method = [\"sum\",\"max\",\"pca\",\"nn\",\"ae\"]\n",
    "ROC(Y_true, Y_scores, method, clf=\"LR\",seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9814c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = 'data/'\n",
    "# Y_scores = pd.DataFrame(Y_scores)\n",
    "# Y_scores.to_csv(file_path + \"scores.csv\", index=False)\n",
    "# Y_scores = Y_scores.values.tolist()\n",
    "\n",
    "# Y_true = pd.DataFrame(Y_true)\n",
    "# Y_true.to_csv(file_path + \"true.csv\", index=False)\n",
    "# Y_true= Y_true.values.tolist()\n",
    "\n",
    "# method = [\"sum\",\"max\",\"pca\",\"nn\",\"ae\"]\n",
    "# ROC(Y_true, Y_scores, method, LR = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b7cad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "# We select several comorbidities and demographics as the predictors.\n",
    "# Since the number of predicitors is not large, so here 'max_features' is not small.\n",
    "param_grid = {\n",
    "    'n_estimators': [100,200,300],  \n",
    "    'max_features': [0.8, 0.9, 1],  \n",
    "    'max_depth': [None, 10, 20, 30],  \n",
    "    'min_samples_split': [2, 5, 10],  \n",
    "    'min_samples_leaf': [1, 2, 4],  \n",
    "    'bootstrap': [True]  \n",
    "}\n",
    "\n",
    "## baseline: orginal data with the max_aggregation covariates\n",
    "# print(\"By Random Forest, result for sum baseline:\")\n",
    "# RF(sum_train,sum_test,params=param_grid)\n",
    "# print(\"By Random Forest, result for max baseline:\")\n",
    "# RF(max_train,max_test,params=param_grid)\n",
    "# ## selected PCA covariates.\n",
    "# print(\"By Random Forest, result for PCA:\")\n",
    "# RF(train,test,params=param_grid)\n",
    "# print(\"By Random Forest, result for NN:\")\n",
    "# RF(nn_train,nn_test,params=param_grid)\n",
    "# print(\"By Random Forest, result for Autoencoder:\")\n",
    "# RF(ae_train,ae_test,params=param_grid)\n",
    "# print(\"By Random Forest, result for NN_RF:\")\n",
    "# RF(nn_rf_train,nn_rf_test,params=param_grid)\n",
    "\n",
    "\n",
    "# print(\"By Random Forest, result for max baseline:\")\n",
    "# RF(max_train,max_test,params=param_grid)\n",
    "# ## selected PCA covariates.\n",
    "# print(\"By Random Forest, result for PCA:\")\n",
    "# RF(train,test,params=param_grid)\n",
    "# print(\"By Random Forest, result for NN:\")\n",
    "# RF(nn_train,nn_test,params=param_grid)\n",
    "# # print(\"By Random Forest, result for NN_RF:\")\n",
    "# # RF(nn_rf_train,nn_rf_test,params=param_grid)\n",
    "# print(\"By Random Forest, result for sum baseline:\")\n",
    "# RF(sum_train,sum_test,params=param_grid)\n",
    "# print(\"By Random Forest, result for Autoencoder:\")\n",
    "# RF(ae_train,ae_test,params=param_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f28f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100,200,300],  \n",
    "    'max_features': [0.8, 0.9, 1],  \n",
    "    'max_depth': [None, 10, 20, 30],  \n",
    "    'min_samples_split': [2, 5, 10],  \n",
    "    'min_samples_leaf': [1, 2, 4],  \n",
    "    'bootstrap': [True]  \n",
    "}\n",
    "Y_scores_sum, accuracy_sum, recall_sum = RF(sum_train,sum_test,tolerance = 1e-4,iter = 4000, seed = 43)\n",
    "Y_scores_max, accuracy_max, recall_max = RF(max_train,max_test,tolerance = 1e-4,iter = 4000, seed = 43)\n",
    "Y_scores_pca, accuracy_pca, recall_pca = RF(train,test,tolerance = 1e-4,iter = 4000, seed = 43)\n",
    "Y_scores_nn, accuracy_nn, recall_nn = RF(nn_train,nn_test,tolerance = 1e-4,iter = 4000, seed = 43)\n",
    "Y_scores_ae, accuracy_ae, recall_ae = RF(ae_train,ae_test,tolerance = 1e-4,iter = 4000, seed = 43)\n",
    "Y_scores = [Y_scores_sum, Y_scores_max, Y_scores_pca, Y_scores_nn, Y_scores_ae]\n",
    "Y_true = test[\"recur_30\"]\n",
    "# file_path = 'data/'\n",
    "# Y_scores.to_csv(\n",
    "#         file_path + \"scores.csv\", index=False)\n",
    "# Y_true.to.to_csv(\n",
    "#         file_path + \"true.csv\", index=False)\n",
    "\n",
    "method = [\"sum\",\"max\",\"pca\",\"nn\",\"ae\"]\n",
    "ROC(Y_true, Y_scores, method, clf=\"RF\",seed=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
