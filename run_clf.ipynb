{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd245785",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BMI PCA data loaded\n",
      "blood_lipids PCA data loaded\n",
      "blood_glucose PCA data loaded\n",
      "hypertensive PCA data loaded\n",
      "nicotine PCA data loaded\n",
      "alcohol PCA data loaded\n",
      "(16612, 22) (4153, 22)\n",
      "(16612, 14) (4153, 14)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from preprocessing import preprocessing\n",
    "from pca import pca_load\n",
    "from pca_all import pca_load_all\n",
    "from baseline import baseline\n",
    "from lr import LR\n",
    "from rf import RF\n",
    "\n",
    "# short code or full code\n",
    "filename = \"main_dataset_final_3\"\n",
    "# filename = \"main_dataset_final_3_full_icd10\"\n",
    "# preprocessing(filename)\n",
    "\n",
    "# binary or continuous\n",
    "datatype = \"binary\"\n",
    "# datatype = \"cont\"\n",
    "X = pd.read_csv(\"data/stroke_data_\" + datatype + \".csv\")\n",
    "X.dropna(inplace=True)\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "\n",
    "disease_mapping = {\n",
    "    #\"BMI\": ['Z68','E65','E66','E67','E68'], \n",
    "    \"BMI\": ['E65','E66'], \n",
    "    \"blood_lipids\": ['E78'],\n",
    "    \"blood_glucose\": ['E10','E11'],\n",
    "    #\"hypertensive\": ['I10','I11','I12','I13','I14','I15','I16'],\n",
    "    \"hypertensive\": ['I10','I11','I12','I13','I15','I16'],\n",
    "    \"nicotine\":['F17','Z72'],\n",
    "    \"alcohol\":['F10']\n",
    "}\n",
    "\n",
    "# pca vs. baseline\n",
    "train, test = pca_load(datatype, disease_mapping, X_train, X_test)\n",
    "# train, test = pca_load_all(datatype, X_train, X_test)\n",
    "base_train, base_test = baseline(datatype, disease_mapping, X_train, X_test)\n",
    "\n",
    "print(train.shape, test.shape)\n",
    "print(base_train.shape, base_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e16955",
   "metadata": {},
   "source": [
    "# Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c4a9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# orginal data with all covariates\n",
    "\n",
    "X = pd.read_csv(\"data/stroke_data_binary.csv\")\n",
    "X.dropna(inplace=True)\n",
    "#X= X[X['race'] != 'Black or African American']\n",
    "or_train, or_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "print(\"By Logistic Regression, result for all original predicitors:\")\n",
    "LR(or_train,or_test,tolerance = 1e-4,iter = 6000, seed = 43)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100,200,300],  \n",
    "    'max_features': [0.2, 0.4, 0.6],  \n",
    "    'max_depth': [None, 10, 20, 30],  \n",
    "    'min_samples_split': [2, 5, 10],  \n",
    "    'min_samples_leaf': [1, 2, 4],  \n",
    "    'bootstrap': [True, False]  \n",
    "}\n",
    "print(\"Result for Random Forest, result for all original predicitors:\")\n",
    "RF(or_train,or_test,params=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70223c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "# We select several comorbidities and demographics as the predictors.\n",
    "\n",
    "## baseline: orginal data with the max_aggregation covariates\n",
    "print(\"By Logistic Regression, result for baseline:\")\n",
    "LR(base_train,base_test,tolerance = 1e-4,iter = 4000, seed = 43)\n",
    "## selected PCA covariates.\n",
    "print(\"By Logistic Regression, result for PCA:\")\n",
    "LR(train,test,tolerance = 1e-4,iter = 4000, seed = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b7cad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "# We select several comorbidities and demographics as the predictors.\n",
    "# Since the number of predicitors is not large, so here 'max_features' is not small.\n",
    "param_grid = {\n",
    "    'n_estimators': [100,200,300],  \n",
    "    'max_features': [0.8, 0.9, 0.95],  \n",
    "    'max_depth': [None, 10, 20, 30],  \n",
    "    'min_samples_split': [2, 5, 10],  \n",
    "    'min_samples_leaf': [1, 2, 4],  \n",
    "    'bootstrap': [True, False]  \n",
    "}\n",
    "\n",
    "## baseline: orginal data with the max_aggregation covariates\n",
    "print(\"By Random Forest, result for baseline:\")\n",
    "RF(base_train,base_test,params=param_grid)\n",
    "## selected PCA covariates.\n",
    "print(\"By Random Forest, result for baseline:\")\n",
    "RF(train,test,params=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1023736d",
   "metadata": {},
   "source": [
    "# Continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ce05be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# short code or full code\n",
    "filename = \"main_dataset_final_3\"\n",
    "# filename = \"main_dataset_final_3_full_icd10\"\n",
    "# preprocessing(filename)\n",
    "\n",
    "# binary or continuous\n",
    "# datatype = \"binary\"\n",
    "datatype = \"cont\"\n",
    "X = pd.read_csv(\"data/stroke_data_\" + datatype + \".csv\")\n",
    "X.dropna(inplace=True)\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "\n",
    "disease_mapping = {\n",
    "    #\"BMI\": ['Z68','E65','E66','E67','E68'], \n",
    "    \"BMI\": ['E65','E66'], \n",
    "    \"blood_lipids\": ['E78'],\n",
    "    \"blood_glucose\": ['E10','E11'],\n",
    "    #\"hypertensive\": ['I10','I11','I12','I13','I14','I15','I16'],\n",
    "    \"hypertensive\": ['I10','I11','I12','I13','I15','I16'],\n",
    "    \"nicotine\":['F17','Z72'],\n",
    "    \"alcohol\":['F10']\n",
    "}\n",
    "\n",
    "# pca vs. baseline\n",
    "train, test = pca_load(datatype, disease_mapping, X_train, X_test)\n",
    "# train, test = pca_load_all(datatype, X_train, X_test)\n",
    "base_train, base_test = baseline(datatype, disease_mapping, X_train, X_test)\n",
    "\n",
    "print(train.shape, test.shape)\n",
    "print(base_train.shape, base_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a81ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# orginal data with all covariates\n",
    "\n",
    "X = pd.read_csv(\"data/stroke_data_cont.csv\")\n",
    "X.dropna(inplace=True)\n",
    "#X= X[X['race'] != 'Black or African American']\n",
    "or_train, or_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "print(\"By Logistic Regression, result for LR:\")\n",
    "LR(or_train,or_test,tolerance = 1e-4,iter = 6000, seed = 43)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100,200,300],  \n",
    "    'max_features': [0.2, 0.4, 0.6],  \n",
    "    'max_depth': [None, 10, 20, 30],  \n",
    "    'min_samples_split': [2, 5, 10],  \n",
    "    'min_samples_leaf': [1, 2, 4],  \n",
    "    'bootstrap': [True, False]  \n",
    "}\n",
    "print(\"By Logistic Regression, result for RF:\")\n",
    "RF(or_train,or_test,params=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d894aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "# We select several comorbidities and demographics as the predictors.\n",
    "\n",
    "## baseline: orginal data with the max_aggregation covariates\n",
    "print(\"Result for baseline:\")\n",
    "LR(base_train,base_test,tolerance = 1e-4,iter = 4000, seed = 43)\n",
    "## selected PCA covariates.\n",
    "print(\"Result for PCA:\")\n",
    "LR(train,test,tolerance = 1e-4,iter = 4000, seed = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcffe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "# We select several comorbidities and demographics as the predictors.\n",
    "# Since the number of predicitors is not large, so here 'max_features' is not small.\n",
    "param_grid = {\n",
    "    'n_estimators': [100,200,300],  \n",
    "    'max_features': [0.8, 0.9, 0.95],  \n",
    "    'max_depth': [None, 10, 20, 30],  \n",
    "    'min_samples_split': [2, 5, 10],  \n",
    "    'min_samples_leaf': [1, 2, 4],  \n",
    "    'bootstrap': [True, False]  \n",
    "}\n",
    "\n",
    "## baseline: orginal data with the max_aggregation covariates\n",
    "print(\"By Random Forest, result for baseline:\")\n",
    "RF(base_train,base_test,params=param_grid)\n",
    "## selected PCA covariates.\n",
    "print(\"By Random Forest, result for PCA:\")\n",
    "RF(train,test,params=param_grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
